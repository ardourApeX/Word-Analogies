{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, encoding = \"utf8\") as file:\n",
    "        text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_data = read_data(\"./data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepika Padukone and Ranveer Singh wedding was one of the biggest Bollywood events that happened in 2018. The Deepika and Ranveer celebrations not only had all of us hooked on to our phones, waiting for what's to come but also gave enough and more reason to believe just how stylish these two are as a couple. From airport looks to reception parties and everything in between here's an entire timeline of Deepika and Ranveer's wedding style file! \n",
      "Not Ambanis, Deepika Ranveer or Priyanka Nick. Man proves his was Wedding of The Year \n",
      "This year was the year of big fat lavish and extravagant weddings. From Isha Ambani and Anand Piramal to Deepika Padukone and Ranveer Singh, from Priyanka Chopra and Nick Jonas to Kapil Sharma and Ginni Chatrath, 2018 saw many grand weddings. But nothing beats this man, who just w on the wedding of The Year award from social media.\n",
      "Priyanka also shared a video featuring Nick Jonas was also celebrating with them \n",
      "The family first celebrated Christmas in London\n",
      "Pictures from Priyanka Chopra and Nick Jonas New Year's celebrations are outstanding. Priyanka Chopra and Nick shared glimpses of the celebration in Verbier, Switzerland. Priyanka Chopra married Nick Jonas in December and after their three wedding receptions - one in New Delhi and two in Mumbai. \n",
      "This year was the year of big fat lavish and extravagant weddings. From Isha Ambani and Anand Piramal to Deepika Padukone and Ranveer Singh, from Priyanka Chopra and Nick Jonas to Kapil Sharma and Ginni Chatrath, 2018 saw many grand weddings. But nothing beats this man, who just won the Wedding of The Year award from social media.\n",
      "Kapil Sharma and Ginni Chatrath's Jaggo night on December 11 was made even more special by their industry friends. Kapil Sharma and Ginni Chatrath are friends for a long time.\n",
      "There, by Virat side was his actress wife Anushka Sharma, who had the pleasure of having an audience with the PM. \n",
      "While the couple rang in the New Year in style, the morning saw Virat dress up in his squad attire and Anushka don a pink Salwar suit.\n",
      "Isha Ambani married Anand Piramal this year.\n"
     ]
    }
   ],
   "source": [
    "print(textual_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Sentence Tokenizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(textual_data)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'didn', 'what', 'while', 'or', 'ours', 'to', 've', 'don', 'me', 'he', 'with', \"isn't\", 'in', \"mightn't\", 'was', 'she', \"don't\", 'on', 'down', 'above', 'd', 'up', 'you', 'been', 'hadn', 'doesn', 'ain', 'theirs', 'if', 'should', 'all', 'is', 'and', 'have', 'as', 'here', 'his', 'just', 'yourself', 'each', 'over', 'mightn', 'those', 'own', \"aren't\", 'other', 'which', 'them', \"you'll\", 'no', 'itself', 'off', 'myself', 'himself', 't', 'some', \"you've\", \"wasn't\", \"couldn't\", 'wasn', 'their', 'but', \"you'd\", 'such', \"shouldn't\", 'few', 'my', 'o', 'does', 'during', \"didn't\", \"hasn't\", 'between', 're', 'of', 'how', 'won', 'now', 'why', 'weren', 'wouldn', 'who', 'there', 'yourselves', 'under', \"hadn't\", 'hers', \"doesn't\", 'mustn', 'doing', 'themselves', 'm', 'can', 'were', 'than', 'at', 'not', 'below', 'that', 'be', 'the', 'this', 'being', 'll', 'am', 'where', 'very', 'hasn', 'once', 'isn', \"shan't\", 'y', 'aren', 'your', 'haven', \"needn't\", 'further', 'too', 'ourselves', \"haven't\", 'against', 'most', 'both', 'same', 'her', \"that'll\", 'then', 'more', 'couldn', 'again', \"wouldn't\", 'out', 'before', 'shan', 'because', 'we', 'into', 'do', 'a', 'through', 'after', 'until', \"should've\", 'its', 'are', 'from', \"won't\", 'needn', 'for', 'only', 'by', \"you're\", 'about', 'nor', 'him', 'whom', \"mustn't\", 'had', 'ma', 'an', 'when', 'it', 'these', 'our', \"it's\", \"weren't\", 'did', 'i', 'they', 'having', 'has', 'shouldn', 'so', 'any', 's', 'yours', \"she's\", 'herself', 'will'}\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if len(word) > 2 and word not in en_stopwords]\n",
    "    list_of_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['the', 'deepika', 'ranveer', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'deepika', 'ranveer', 'wedding', 'style', 'file'], ['not', 'ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'the', 'year', 'this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['priyanka', 'also', 'shared', 'video', 'featuring', 'nick', 'jonas', 'also', 'celebrating', 'the', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'priyanka', 'chopra', 'nick', 'jonas', 'new', 'year', 'celebrations', 'outstanding'], ['priyanka', 'chopra', 'nick', 'shared', 'glimpses', 'celebration', 'verbier', 'switzerland'], ['priyanka', 'chopra', 'married', 'nick', 'jonas', 'december', 'three', 'wedding', 'receptions', 'one', 'new', 'delhi', 'two', 'mumbai'], ['this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['kapil', 'sharma', 'ginni', 'chatrath', 'jaggo', 'night', 'december', 'made', 'even', 'special', 'industry', 'friends'], ['kapil', 'sharma', 'ginni', 'chatrath', 'friends', 'long', 'time'], ['there', 'virat', 'side', 'actress', 'wife', 'anushka', 'sharma', 'pleasure', 'audience'], ['while', 'couple', 'rang', 'new', 'year', 'style', 'morning', 'saw', 'virat', 'dress', 'squad', 'attire', 'anushka', 'pink', 'salwar', 'suit'], ['isha', 'ambani', 'married', 'anand', 'piramal', 'year']]\n"
     ]
    }
   ],
   "source": [
    "print(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=115, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(list_of_words, size = 300, window = 10, min_count = 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018', 'the', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple', 'from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'style', 'file', 'not', 'ambanis', 'priyanka', 'nick', 'man', 'proves', 'year', 'this', 'big', 'fat', 'lavish', 'extravagant', 'weddings', 'isha', 'ambani', 'anand', 'piramal', 'chopra', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', 'saw', 'many', 'grand', 'but', 'nothing', 'beats', 'award', 'social', 'media', 'shared', 'video', 'featuring', 'celebrating', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'new', 'outstanding', 'glimpses', 'celebration', 'verbier', 'switzerland', 'married', 'december', 'three', 'receptions', 'delhi', 'mumbai', 'jaggo', 'night', 'made', 'even', 'special', 'industry', 'friends', 'long', 'time', 'there', 'virat', 'side', 'actress', 'wife', 'anushka', 'pleasure', 'audience', 'while', 'rang', 'morning', 'dress', 'squad', 'attire', 'pink', 'salwar', 'suit']\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(model[\"deepika\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(a, b, c, word_vectors):\n",
    "    '''a, b, c => Triad ::  a -> b : c -> ?'''\n",
    "    a, b, c = a.lower(), b.lower(), c.lower()\n",
    "    max_similarity = -1\n",
    "    d = None\n",
    "    \n",
    "    vector_a, vector_b, vector_c = word_vectors[a], word_vectors[b], word_vectors[c]\n",
    "    celebs = [\"deepika\", \"singh\", \"ranveer\", \"ginni\", \"virat\", \"priyanka\", \"jonas\", \"nick\", \"chopra\", \"padukone\", \"anushka\"]\n",
    "    \n",
    "    for gonna_d in celebs:\n",
    "        if gonna_d in [a, b, c]:\n",
    "            continue\n",
    "        vector_d = word_vectors[gonna_d]\n",
    "        similarity = cosine_similarity([vector_b - vector_a], [vector_d - vector_c])\n",
    "        \n",
    "        if max_similarity < similarity:\n",
    "            max_similarity = similarity\n",
    "            d = gonna_d\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'priyanka'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"deepika\", \"ranveer\", \"nick\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'padukone'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"ranveer\", \"singh\", \"deepika\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
